{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMCYy8kk4Yg89tMSRFlmtN/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"8phjJYkJ1hMi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","\n","url = \"https://www.reddit.com/r/news/\"  # URL of the Reddit \"r/news\" subreddit\n","\n","headers = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"}\n","\n","response = requests.get(url, headers=headers)\n","\n","if response.status_code == 200:\n","    page_content = response.content\n","else:\n","    print(\"Failed to retrieve the page content.\")\n","    exit()\n","\n","soup = BeautifulSoup(page_content, 'html.parser')\n","\n","# Extract and print titles of the top posts\n","post_titles = soup.find_all('h3', class_='_eYtD2XCVieq6emjKBH3m')\n","for title in post_titles:\n","    print(\"Title:\", title.get_text())\n"],"metadata":{"id":"YRQ5rcVF1f87"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files"],"metadata":{"id":"7QaIRfSF1kiy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","\n","url = \"https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_and_their_capitals_in_native_languages\"\n","\n","response = requests.get(url)\n","\n","if response.status_code != 200:\n","    exit()\n","\n","page_content = response.content\n","soup = BeautifulSoup(page_content, 'html.parser')\n","\n","# Find the table containing the list of countries and capitals\n","table = soup.find('table', class_='wikitable')\n","\n","# Extract and print the countries and capitals\n","rows = table.find_all('tr')[1:]  # Exclude the header row\n","\n","for row in rows:\n","    columns = row.find_all('td')\n","    country = columns[0].text.strip()\n","    capital = columns[1].text.strip()\n","    print(\"Country:\", country)\n","    print(\"Capital:\", capital)\n","    print()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RaPBqJP82gfK","executionInfo":{"status":"ok","timestamp":1693372262921,"user_tz":-330,"elapsed":925,"user":{"displayName":"Varshini S","userId":"10612217733965148061"}},"outputId":"fdaf2edc-70f0-4ead-cedf-39665ef08184"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Country: Afghanistan\n","Capital: Kabul\n","\n","Country: Albania\n","Capital: Tirana\n","\n","Country: Algeria\n","Capital: Algiers\n","\n","Country: American Samoa[1]\n","Capital: Pago Pago\n","\n","Country: Andorra\n","Capital: Andorra la Vella\n","\n","Country: Angola\n","Capital: Luanda\n","\n","Country: Anguilla[2]\n","Capital: The Valley\n","\n","Country: Antigua and Barbuda\n","Capital: Saint John's\n","\n","Country: Argentina\n","Capital: Buenos Aires\n","\n","Country: Armenia\n","Capital: Yerevan\n","\n","Country: Aruba[3]\n","Capital: Oranjestad\n","\n","Country: Australia\n","Capital: Canberra\n","\n","Country: Austria\n","Capital: Vienna\n","\n","Country: Ã…land[4]\n","Capital: Mariehamn\n","\n","Country: Azerbaijan\n","Capital: Baku\n","\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.download('wikipedia.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":314},"id":"s6xtaDpf2mcJ","executionInfo":{"status":"error","timestamp":1693372547330,"user_tz":-330,"elapsed":479,"user":{"displayName":"Varshini S","userId":"10612217733965148061"}},"outputId":"1f9b9850-8f16-4c47-ff4c-facdad032d33"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-83fc1f034e2c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wikipedia.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    223\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: wikipedia.csv"]}]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import csv\n","\n","url = \"https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_and_their_capitals_in_native_languages\"\n","\n","response = requests.get(url)\n","\n","if response.status_code == 200:\n","    page_content = response.content\n","    soup = BeautifulSoup(page_content, 'html.parser')\n","\n","    # Find the table containing the list of countries and capitals\n","    table = soup.find('table', class_='wikitable')\n","\n","    # Extract and write the countries and capitals to a CSV file\n","    rows = table.find_all('tr')[1:]  # Exclude the header row\n","\n","    with open('countries_and_capitals.csv', 'w', newline='', encoding='utf-8') as csvfile:\n","        csv_writer = csv.writer(csvfile)\n","        csv_writer.writerow([\"Country\", \"Capital\"])  # Write header\n","\n","        for row in rows:\n","            columns = row.find_all('td')\n","            country = columns[0].text.strip()\n","            capital = columns[1].text.strip()\n","            csv_writer.writerow([country, capital])\n","\n","    print(\"Data has been written to 'countries_and_capitals.csv'.\")\n","else:\n","    print(\"Failed to retrieve the page content.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ivzcPS294jtN","executionInfo":{"status":"ok","timestamp":1693372872274,"user_tz":-330,"elapsed":997,"user":{"displayName":"Varshini S","userId":"10612217733965148061"}},"outputId":"7471b367-41b6-4097-9d88-063b54daf1f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data has been written to 'countries_and_capitals.csv'.\n"]}]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import csv\n","\n","url = \"https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_and_their_capitals_in_native_languages\"\n","\n","response = requests.get(url)\n","\n","if response.status_code == 200:\n","    page_content = response.content\n","    soup = BeautifulSoup(page_content, 'html.parser')\n","\n","    # Find the table containing the list of countries and capitals\n","    table = soup.find('table', class_='wikitable')\n","\n","    # Extract and write the countries and capitals to a CSV file\n","    rows = table.find_all('tr')[1:]  # Exclude the header row\n","\n","    csv_file_path = 'countries_and_capitals.csv'\n","    with open(csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n","        csv_writer = csv.writer(csvfile)\n","        csv_writer.writerow([\"Country\", \"Capital\"])  # Write header\n","\n","        for row in rows:\n","            columns = row.find_all('td')\n","            country = columns[0].text.strip()\n","            capital = columns[1].text.strip()\n","            csv_writer.writerow([country, capital])\n","\n","    print(f\"Data has been written to '{csv_file_path}'.\")\n","\n","    # Download the CSV file\n","    with open(csv_file_path, 'rb') as file:\n","        data = file.read()\n","        with open('downloaded_countries_and_capitals.csv', 'wb') as download_file:\n","            download_file.write(data)\n","    print(\"CSV file has been downloaded.\")\n","else:\n","    print(\"Failed to retrieve the page content.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"flWzpH_H5Y3I","executionInfo":{"status":"ok","timestamp":1693393696303,"user_tz":-330,"elapsed":1240,"user":{"displayName":"Varshini S","userId":"10612217733965148061"}},"outputId":"849099ee-a916-4100-e2bd-a60e14156c9d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Data has been written to 'countries_and_capitals.csv'.\n","CSV file has been downloaded.\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.download('downloaded_countries_and_capitals.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"w-fcMwUb5agO","executionInfo":{"status":"ok","timestamp":1693393700925,"user_tz":-330,"elapsed":480,"user":{"displayName":"Varshini S","userId":"10612217733965148061"}},"outputId":"3a6770d1-ae21-47b1-f7ba-98b856af088b"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_39883afd-b5d1-44c1-a3ca-fc4db36f8ad7\", \"downloaded_countries_and_capitals.csv\", 333)"]},"metadata":{}}]}]}